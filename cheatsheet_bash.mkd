# df - to check free disk space

Type df -h or df -k to list free disk space:

    $ df -h

OR

    $ df -k

# Pass command line argument to bash alias command

    function foo() { /path/to/command "$@" ;}

Now you can call foo():
foo arg1 arg2 argN
(see http://www.cyberciti.biz/faq/linux-unix-pass-argument-to-alias-command/)

# diff

## find out difference between folders

    diff -rq folder1 folder2

-r  look at each directory recursively
-q  sets diff brief mode

# cut and paste

## count loc in a codebase

* find all source code files
* count number of lines for each
* cut out only the number
* combine the numbers from stdin with +
* feed the resulting string to bc

    find -E . -regex ".*\.(cpp|c|h|hpp)" | xargs -n1 wc -l | cut -f1 -d'.' | paste -sd+ - | bc

# zip

## unzip multipart zip file

    cat zipfileparts.* > combined.zip
    zip -F combined.zip --out fixed.zip
    unzip fixed.zip

## create a file "archivefile1.zip" which contains a copy of the files doc1, doc2, and doc3

    zip archivefile1 doc1 doc2 doc3

## copies the directory "papers" into "archivefile2.zip". 

    zip -r archivefile2 papers

## extract 7z

    p7zip -d filename.7z

## writes the files extracted from "archivefile1.zip" to the current directory. 

    unzip archivefile1.zip

# Run a Command Repeatedly and Display the Output

watch runs command repeatedly, displaying its output (the first screenfull). This allows you to watch the program output change over time. By default, the program is run every 2 seconds. watch is very similar to tail.

    $ watch -n 60 ls -l # will execute ls -l every minute

# print sizes of folders sorted by size

    $ du -s ./* | sort -n | cut -f 2- | xargs -Ix du -sh x

# what every Linux user should know
(taken from http://www.xydo.com/toolbar/17462376-what_are_some_lesser_known_but_useful_unix_commands)
  
## Basics

* Learn basic bash. Actually, read the whole bash man page; it's pretty easy to follow and not that long. Alternate shells can be nice, but bash is powerful and always available (learning mainly zsh or tcsh restricts you in many situations).
* Learn vim. There's really no competition for random Linux editing (even if you use Emacs or Eclipse most of the time).
* Know ssh, and the basics of passwordless authentication, via ssh-agent, ssh-add, etc.
* Be familiar with bash job management: &, Ctrl-Z, Ctrl-C, jobs, fg, bg, kill, etc.
* Basic file management: ls and ls -l (in particular, learn what every column in "ls -l" means), less, head, tail and tail -f, ln and ln -s (learn the differences and advantages of hard versus soft links), chown, chmod, du (for a quick summary of disk usage: du -sk *), df, mount.
* Basic network management: ip or ifconfig, dig.
* Know regular expressions well, and the various flags to grep/egrep. The -o, -A, and -B options are worth knowing.
* Learn to use aptitude or yum (depending on distro) to find and install packages.

## Everyday use
* In bash, use Ctrl-R to search through command history.
* In bash, use Ctrl-W to kill the last word, and Ctrl-U to kill the line. See man readline for default keybindings in bash. There are a lot. For example Alt-. cycles through prevous arguments, and Alt-* expands a glob.
* To go back to the previous working directory: cd -
* Use xargs (or parallel). It's very powerful. Note you can control how many items execute per line (-L) as well as parallelism (-P). If you're not sure if it'll do the right thing, use xargs echo first. Also, -I{} is handy. Examples:
* find . -name \*.py | xargs grep some_function
* cat hosts | xargs -I{} ssh root@{} hostname
* pstree -p is a helpful display of the process tree.
* Use pgrep and pkill to find or signal processes by name (-f is helpful).
* Know the various signals you can send processes. For example, to suspend a process, use kill -STOP [pid].  For the full list, see man 7 signal
* Use nohup or disown if you want a background process to keep running forever.
* Check what processes are listening via netstat -lntp. See also lsof.
* In bash scripts, use set -x for debugging output. Use set -e to abort on errors. Consider using set -o pipefail as well, to be strict about errors (though this topic is a bit subtle). For more involved scripts, also use trap.
* In bash scripts, subshells (written with parentheses) are convenient ways to group commands. A common example is to temporarily move to a different working directory, e.g.

    # do something in current dir
    (cd /some/other/dir; other-command)
    # continue in original dir

* In bash, note there are lots of kinds of variable expansion. Checking a variable exists: ${name:?error message}. For example, if a bash script requires a single argument, just write input_file=${1:?usage: $0 input_file}. Arithmetic expansion: i=$(( (i + 1) % 5 )). Sequences: {1..10}. Trimming of strings: ${var%suffix} and ${var#prefix}. For example if var=foo.pdf, then echo ${var%.pdf}.txt prints "foo.txt".
* The output of a command can be treated like a file via <(some command). For example, compare local /etc/hosts with a remote one: diff /etc/hosts <(ssh somehost cat /etc/hosts)
* Know about "here documents" in bash, as in cat <<EOF ....
* In bash, redirect both standard output and standard error via: some-command >logfile 2>&1. Often, to ensure a command does not leave an open file handle to standard input, tying it to the terminal you are in, it is also good practice to add "</dev/null".
* Use man ascii for a good ASCII table, with hex and decimal values.
* On remote ssh sessions, use screen or dtach to save your session, in case it is interrupted.
* For web debugging, curl and curl -I are handy, and/or their wget equivalents.
* To convert HTML to text: lynx -dump -stdin
* If you must handle XML, xmlstarlet is good.
* For Amazon S3, s3cmd is convenient (albeit immature, with occasional misfeatures).
* In ssh, knowing how to port tunnel with -L or -D (and occasionally -R) is useful, e.g. to access web sites from a remote server.
* It can be useful to make a few optimizations to your ssh configuration; for example, this .ssh/config contains settings to avoid dropped connections in certain network environments, not require confirmation connecting to new hosts, forward authentication, and use compression (which is helpful with scp over low-bandwidth connections):

    TCPKeepAlive=yes
    ServerAliveInterval=15
    ServerAliveCountMax=6
    StrictHostKeyChecking=no
    Compression=yes
    ForwardAgent=yes

* If you are halfway through typing a command but change your mind, hit Alt-# to add a # at the beginning and enter it as a comment (or use Ctrl-A, #, enter). You can then return to it later via command history.

## Data processing
* Know about sort and uniq (including uniq's -u and -d options).
* Know about cut, paste, and join to manipulate text files. Many people use cut but forget about join.
* It is remarkably helpful sometimes that you can do set intersection, union, and difference of text files via sort/uniq. Suppose a and b are text files that are already uniqued. This is fast, and works on files of arbitrary size, up to many gigabytes. (Sort is not limited by memory, though you may need to use the -T option if /tmp is on a small root partition.)
* cat a b | sort | uniq > c   # c is a union b
* cat a b | sort | uniq -d > c   # c is a intersect b
* cat a b b | sort | uniq -u > c   # c is set difference a - b
* Know that locale affects a lot of command line tools, including sorting order and performance. Most Linux installations will set LANG or other locale variables to a local setting like US English. This can make sort or other commands run many times slower. (Note that even if you use UTF-8 text, you can safely sort by ASCII order for many purposes.) To disable slow i18n routines and use traditional byte-based sort order, use export LC_ALL=C (in fact, consider putting this in your .bashrc).
* Know basic awk for simple data munging. For example, summing all numbers in the third column of a text file: awk '{ x += $3 } END { print x }'. This is probably 3X faster and 3X shorter than equivalent Python.
* Use shuf to shuffle or select random lines from a file.
* Know sort's options. Know how keys work (-t and -k). In particular, watch out that you need to write -k1,1 to sort by only the first field; -k1 means sort according to the whole line.
* Stable sort (sort -s) can be useful. For example, to sort first by field 2, then secondarily by field 1, you can use sort -k1,1 | sort -s -k2,2
* If you ever need to write a tab literal in a command line in bash (e.g. for the -t argument to sort), press Ctrl-V <tab>.
* For binary files, use hd for simple hex dumps and bvi for binary editing.
* Also for binary files, strings (plus grep, etc.) lets you find bits of text.
* To convert text encodings, try iconv. Or uconv for more advanced use (it supports some advanced Unicode things, such as transforms for normalization, accent removal, etc.).
* To split files into pieces, see split (to split by size) and csplit (to split by a pattern).

## System debugging
* To know disk/cpu/network status, use iostat, netstat, top (or the better htop), and (especially) dstat. Good for getting a quick idea of what's happening on a system.
* To know memory status, run and understand the output of free. In particular, be aware the "cached" value is memory held by the Linux kernel as file cache, so effectively counts toward the "free" value.
* Java system debugging is different kettle of fish, but a simple trick on Sun's and some other JVMs is that you can run kill -3 <pid> and they will dump a full stack trace and heap summary (including generational garbage collection details) to stderr/logs.
* Use mtr as a better traceroute, to identify network issues.
* To find which socket or process is using bandwidth, try iftop or nethogs.
* The ab tool (comes with Apache) is helpful for quick-and-dirty checking of web server performance.
* For more serious network debugging, wireshark or tshark.
* Know strace, and that you can strace a running process (with -p). This can be helpful if a program is failing, hanging, or crashing, and you don't know why.
* Know about ldd to check shared libraries etc.
* Know how to connect to a running process with gdb and get its stack traces.
* Use /proc. It's amazingly helpful sometimes when debugging live problems. Examples: /proc/cpuinfo, /proc/xxx/cwd, /proc/xxx/exe, /proc/xxx/fd/, /proc/xxx/smaps.
* When debugging why something went wrong in the past, sar can be very helpful. It shows historic statistics on CPU, memory, network, etc.
* Use dmesg whenever something's acting really funny (it could be hardware or driver issues).

# What are some lesser known but useful Unix commands?
  
* m4: simple macro processor
* yes: print a string a lot
* seq: print numbers
* cal: nice calendar
* env: run a command (useful in scripts)
* look: find English words (or lines in a file) beginning with a string
* cut and paste and join: data manipulation
* bc: calculator

## Formatting

* fmt: format text paragraphs
* pr: format text into pages/columns
* fold: wrap lines of text
* column: format text into columns or tables
* expand and unexpand: convert between tabs and spaces
* nl: add line numbers

## Networking

* nc: network debugging and data transfer
* mtr: better traceroute for network debugging
* wireshark and tshark: packet capture and network debugging
* host and dig: DNS lookups
* lsof: process file descriptor and socket info
* ab: benchrmarking web servers
* ss: socket statistics

## Filesystem
* dd: moving data between files or devices
* file: identify type of a file
* ldd: dynamic library info
* stat: file info
* tac: print files in reverse
* shuf: random selection of lines from a file
* comm: compare sorted files line by line
* hd and bvi: dump or edit binary files
* strings: extract text from binary files
* tr: character translation or manipulation
* iconv or uconv: conversion for text encodings
* split and csplit: splitting files
* 7z: high-ratio file compression
* nm: symbols from object files

## Systeminfo

* strace: system call debugging
* cssh: visual concurrent shell
* dstat: useful system stats
* iostat: CPU and disk usage stats
* htop: improved version of top
* last: login history
* w: who's logged on
* id: user/group identity info
* sar: historic system stats
* iftop or nethogs: network utilization by socket or process
* dmesg: boot and system error messages
* (Linux) hdparm: SATA/ATA disk manipulation/performance
* (Linux) lsb_release: Linux distribution info
* (Linux) lshw: hardware information

# man
    
## find manpages for a specific topic

    $ man -k xxx  -- will list all manpages that contain information about xxx

# seq command

    $ seq 5 -- prints numbers from 1 to 5
    $ seq 5 10
    $ seq 0 2 10
    $ seq 5 -1 1

# find

    find . -name *exe | ack.pl -i unittest

### find all files that are executable

    find <dir> -executable -type f

### find all files with multiple patterns

    find . -name "*.cpp" -or -name "*.h"

### touch all files in directory recursively

    find . -exec touch {} \;

### copy multiple files (e.g. all files starting with 'one' into dir 'play')

    find -name "one*" -exec cp "{}" play \;

### using xargs

    find -name "one*" -print0 | xargs -0 cp -t play

### find all files that have a .xls or .csv extension?

    find -name "*.xls" -o -name "*.csv"
    find -regex ".*\.\(xls\|csv\)"

### filter out stuff

    find . -iregex '.*debug.*.o' | grep -v Bootloader

# ack

### search for all "assert(" strings in any cpp or h file

    ack 'assert\(' -G '.*\.(cpp|h)'

# for loops

### loop over range (> bash version 3)

    $ for i in {1..12}; do cal -m $i; done

### Bash substitution

    $ for i in *.flv; do echo original: "$i" , substituted: "${i/.flv/.mp3}"; done

### do s.th. for each file

    for n in `ls -d */`;do cd $n; echo "-------" `pwd`;ack.pl .*exe$; cd ..; done
    for n in `cat  unittest.txt`;do echo "-------" $n; done

### find all unit tests and execute those:

    for n in `find . -name *exe | ack.pl -i unittest`;do $n; done

### find out which files are executable:

    for n in `find . -name *.a`;do if [ -x "$n" ]; then echo "$n yea"; else echo no$n;fi; done

    alphabet="a b c d e"					# Initialise a string
    count=0									# Initialise a counter
    for letter in $alphabet					# Set up a loop control
    do										# Begin the loop
        count=`expr $count + 1`				# Increment the counter
        echo "Letter $count is [$letter]"	# Display the result
    done									# End of loop

# script files

### for a new script file: 

    touch myScript.sh

### start with #!/bin/sh

    echo "#!/bin/sh" >> myScript.sh

# Job Control

    $ [crtl]+z        # Stop (don't kill) the foreground job, and then return to the shell
    $ bg              # Run the most recently stopped job in background
    $ jobs            # Check the status of jobs in current session
    $ ps -u username  # Check the status of processes, including those from other sessions (On BSD systems, use 'ps -gx')
    $ fg              # Bring most recently backgrounded job to foreground
    $ disown          # disown to avoid killing the process after you close the terminal

# chown

### recursively change the owner to oliver and group to admin

    $ sudo chown -R  oliver:admin dev

# change routing for one ip:

    $ sudo route del -net 169.254.0.0 netmask 255.255.0.0 dev eth2
    $ sudo route add -net 169.254.0.0 netmask 255.255.0.0 dev eth0 
(will route on eth0)

# change stati ip:

    $ sudo ifconfig eth0 160.48.199.101 netmask 255.255.0.0 up

# du usage

    du -h --max-depth=1

### make file executable

    chmod 755 myScript.sh	

### Run the last command as root

    sudo !!

### Rapidly invoke an editor to write a long, complex, or tricky command

    ctrl-x ctrl-e

### Execute a command at a given time

    echo "ls -l" | at midnight

### secure copy, e.g. copy ssh keys:

    scp -i /home/myuser/.ssh/oliver.pub /home/myuser/.ssh/id_rsa.pub   linux2@10.40.39.53:tmp/id_rsa.pub



